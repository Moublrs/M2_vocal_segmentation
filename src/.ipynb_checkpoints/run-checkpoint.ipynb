{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b189666ecf39b2b",
   "metadata": {},
   "source": [
    "# DATA LOADER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195f407-655c-4309-a393-53bedae16efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!python model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ba907ff2de547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tracks=[]\n",
    "dir_spec_train = Path.home() / \"TP SON UNET\" / \"data\" / \"spec_data\" / \"train\"\n",
    "for track_folder in dir_spec_train.iterdir():\n",
    "    length=np.load(track_folder / \"mixture_db.npy\").shape[1]\n",
    "    track={\n",
    "        \"mix\" : track_folder / \"mixture_db.npy\",\n",
    "        \"vocals\": track_folder / \"vocals_db.npy\",\n",
    "        \"nb_frames\" :(length - frame_size) // stride\n",
    "    }\n",
    "    tracks.append(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d138611824f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.randint(0, 5, (100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf492045f7546339",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = [\n",
    "    {\n",
    "        \"mix\": \"track_01/mixture_db.npy\",\n",
    "        \"vocals\": \"track_01/vocals_db.npy\",\n",
    "        \"nb_frames\": 1921\n",
    "    },\n",
    "    {\n",
    "        \"mix\": \"track_02/mixture_db.npy\",\n",
    "        \"vocals\": \"track_02/vocals_db.npy\",\n",
    "        \"nb_frames\": 1921\n",
    "    },\n",
    "    {\n",
    "        \"mix\": \"track_03/mixture_db.npy\",\n",
    "        \"vocals\": \"track_03/vocals_db.npy\",\n",
    "        \"nb_frames\": 1853\n",
    "    },\n",
    "    {\n",
    "        \"mix\": \"track_04/mixture_db.npy\",\n",
    "        \"vocals\": \"track_04/vocals_db.npy\",\n",
    "        \"nb_frames\": 1973\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7077049627bd5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_tracks = torch.randint(0,len(tracks), (2,))\n",
    "\n",
    "nb_frames_list = [\n",
    "    tracks[i][\"nb_frames\"]\n",
    "    for i in idx_tracks.tolist()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd00d752cd053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493c67a8dcceac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_tracks = torch.randint(0, len(tracks), (32,))\n",
    "nb_frames_list = [\n",
    "            tracks[i][\"nb_frames\"]\n",
    "            for i in idx_tracks.tolist()\n",
    "        ]\n",
    "frames = [torch.randint(0, nb_frame, (1,)).item() for nb_frame in nb_frames_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0efb2324b42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa05a495122497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dir_spec_train = Path.home() / \"TP SON UNET\" / \"data\" / \"spec_data\" / \"train\"\n",
    "mix=np.load(dir_spec_train /\"A Classic Education - NightOwl_mixture\"/\"mixture_db.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491388f39e82a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_norm = (mix - mix.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660783d76d5a011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_mix = mix.std() + 1e-8\n",
    "mix_norm = (mix - mix.mean()) / std_mix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eea17750816b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4274a8379087bfd",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc732f7bb4cad701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T03:40:25.324413Z",
     "start_time": "2026-01-02T03:40:16.802119Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "[0/50000] loss = 0.005498\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "[100/50000] loss = 0.004952\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "[200/50000] loss = 0.003319\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "input image : torch.Size([32, 1, 512, 128])\r\n",
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/mouad/TP SON UNET/src/train.py\", line 69, in <module>\r\n",
      "    loss.backward()\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 521, in backward\r\n",
      "    torch.autograd.backward(\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 289, in backward\r\n",
      "    _engine_run_backward(\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\r\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\r\n",
      "KeyboardInterrupt\r\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/utils/_process_posix.py:156\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/spawnbase.py:383\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython train.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/utils/_process_posix.py:180\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    182\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/pty_spawn.py:642\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGHUP)\n\u001b[0;32m--> 642\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63d84a4-fd77-43ee-9529-3e2c837f10ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41510/73222160.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: vocals_pred.wav\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "from model import UNet\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Paths\n",
    "# =========================\n",
    "TRACK_DIR = Path.home() / \"TP SON UNET\" / \"data\" / \"spec_data_linear\" / \"test\" / \"Little Chicago's Finest - My Own_mixture\"\n",
    "MODEL_PATH = \"unet_final.pth\"\n",
    "OUT_WAV = \"vocals_pred.wav\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Params (match training)\n",
    "# =========================\n",
    "SR = 8192\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 768\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "FRAME_SIZE = 128\n",
    "STRIDE = 1   # 1 = tr√®s lent ; 32/64 = test rapide\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load model\n",
    "# =========================\n",
    "model = UNet().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load spectrogram data (513 bins on disk)\n",
    "# =========================\n",
    "mix_mag_513 = np.load(TRACK_DIR / \"mixture_linear.npy\").astype(np.float32)      # (513, T) normalized\n",
    "mix_phase_513 = np.load(TRACK_DIR / \"mixture_phase.npy\").astype(np.float32)    # (513, T)\n",
    "mix_max = np.load(TRACK_DIR / \"mix_max.npy\").astype(np.float32)                # scalar\n",
    "\n",
    "F513, T = mix_mag_513.shape\n",
    "assert F513 == 513, f\"Expected 513 freq bins on disk, got {F513}\"\n",
    "\n",
    "# =========================\n",
    "# Drop Nyquist for the model -> 512 bins (as in the paper diagram)\n",
    "# =========================\n",
    "mix_mag_512 = mix_mag_513[:-1, :]      # (512, T)\n",
    "mix_phase_512 = mix_phase_513[:-1, :]  # (512, T) (used only inside patches if needed)\n",
    "\n",
    "F, T = mix_mag_512.shape\n",
    "assert F == 512, f\"Expected 512 bins for the model, got {F}\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Patch-based inference (overlap-add) in 512-bin space\n",
    "# =========================\n",
    "voc_norm_512 = np.zeros((F, T), dtype=np.float32)\n",
    "weight = np.zeros((F, T), dtype=np.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t0 in range(0, T - FRAME_SIZE + 1, STRIDE):\n",
    "        mix_patch = mix_mag_512[:, t0:t0 + FRAME_SIZE]  # (512, 128)\n",
    "        mix_t = torch.from_numpy(mix_patch).unsqueeze(0).unsqueeze(0).to(DEVICE)  # (1,1,512,128)\n",
    "\n",
    "        mask_patch = model(mix_t).squeeze().cpu().numpy().astype(np.float32)      # (512,128)\n",
    "        voc_patch = mask_patch * mix_patch                                        # (512,128)\n",
    "\n",
    "        voc_norm_512[:, t0:t0 + FRAME_SIZE] += voc_patch\n",
    "        weight[:, t0:t0 + FRAME_SIZE] += 1.0\n",
    "\n",
    "# Handle tail if STRIDE doesn't land exactly on the last window\n",
    "last_start = T - FRAME_SIZE\n",
    "if last_start > 0 and (T - FRAME_SIZE) % STRIDE != 0:\n",
    "    with torch.no_grad():\n",
    "        mix_patch = mix_mag_512[:, last_start:last_start + FRAME_SIZE]\n",
    "        mix_t = torch.from_numpy(mix_patch).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        mask_patch = model(mix_t).squeeze().cpu().numpy().astype(np.float32)\n",
    "        voc_patch = mask_patch * mix_patch\n",
    "\n",
    "        voc_norm_512[:, last_start:last_start + FRAME_SIZE] += voc_patch\n",
    "        weight[:, last_start:last_start + FRAME_SIZE] += 1.0\n",
    "\n",
    "voc_norm_512 /= np.maximum(weight, 1.0)\n",
    "\n",
    "# De-normalize back to original magnitude scale\n",
    "voc_mag_512 = voc_norm_512 * mix_max\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Restore Nyquist bin (513th row) with zeros, then ISTFT with n_fft=1024\n",
    "# =========================\n",
    "nyquist_row = np.zeros((1, T), dtype=np.float32)\n",
    "voc_mag_513 = np.vstack([voc_mag_512, nyquist_row])  # (513, T)\n",
    "\n",
    "# Complex STFT using MIX phase (full 513 bins)\n",
    "voc_stft_513 = voc_mag_513 * np.exp(1j * mix_phase_513)\n",
    "\n",
    "# ISTFT with the original FFT size\n",
    "voc_audio = librosa.istft(\n",
    "    voc_stft_513,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    win_length=N_FFT\n",
    ")\n",
    "\n",
    "sf.write(OUT_WAV, voc_audio, SR)\n",
    "print(\"Saved:\", OUT_WAV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26132d6e-9301-4957-9ce5-1496ad0291f1",
   "metadata": {},
   "source": [
    "# MP3 song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25995b32-7821-4f91-b3d7-1f4a330e0b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41510/2214797945.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: vocals_pred.wav\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "from model import UNet\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Paths (edit these)\n",
    "# =========================\n",
    "MP3_PATH = Path(\"Party.mp3\")     # mixture audio (mp3)\n",
    "MODEL_PATH = Path(\"unet_final.pth\")\n",
    "OUT_WAV = Path(\"vocals_pred.wav\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Params (must match training)\n",
    "# =========================\n",
    "SR = 8192\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 768\n",
    "\n",
    "FRAME_SIZE = 128          # model patch width in frames\n",
    "STRIDE_FRAMES = 1        # overlap-add stride in frames (32/64 good for speed)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load model\n",
    "# =========================\n",
    "model = UNet().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load mp3 -> STFT (513 bins)\n",
    "# =========================\n",
    "y, _ = librosa.load(str(MP3_PATH), sr=SR, mono=True)\n",
    "\n",
    "stft_mix = librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "mix_mag_513 = np.abs(stft_mix).astype(np.float32)          # (513, T)\n",
    "mix_phase_513 = np.angle(stft_mix).astype(np.float32)      # (513, T)\n",
    "\n",
    "mix_max = float(mix_mag_513.max() + 1e-8)                  # avoid div by 0\n",
    "mix_mag_513_norm = (mix_mag_513 / mix_max).astype(np.float32)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Drop Nyquist bin for the model (512 bins)\n",
    "# =========================\n",
    "mix_mag_512 = mix_mag_513_norm[:-1, :]                     # (512, T)\n",
    "F, T = mix_mag_512.shape\n",
    "assert F == 512, f\"Expected 512 bins for model input, got {F}\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Patch-based inference (overlap-add) in 512-bin space\n",
    "# =========================\n",
    "voc_norm_512 = np.zeros((F, T), dtype=np.float32)\n",
    "weight = np.zeros((F, T), dtype=np.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t0 in range(0, T - FRAME_SIZE + 1, STRIDE_FRAMES):\n",
    "        mix_patch = mix_mag_512[:, t0:t0 + FRAME_SIZE]  # (512, 128)\n",
    "        mix_t = torch.from_numpy(mix_patch).unsqueeze(0).unsqueeze(0).to(DEVICE)  # (1,1,512,128)\n",
    "\n",
    "        mask_patch = model(mix_t).squeeze().cpu().numpy().astype(np.float32)      # (512,128)\n",
    "        voc_patch = mask_patch * mix_patch                                        # (512,128)\n",
    "\n",
    "        voc_norm_512[:, t0:t0 + FRAME_SIZE] += voc_patch\n",
    "        weight[:, t0:t0 + FRAME_SIZE] += 1.0\n",
    "\n",
    "\n",
    "\n",
    "voc_norm_512 /= np.maximum(weight, 1.0)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# De-normalize + restore Nyquist bin + ISTFT (n_fft=1024)\n",
    "# =========================\n",
    "voc_mag_512 = voc_norm_512 * mix_max                        # back to original scale\n",
    "\n",
    "nyquist_row = np.zeros((1, T), dtype=np.float32)\n",
    "voc_mag_513 = np.vstack([voc_mag_512, nyquist_row])         # (513, T)\n",
    "\n",
    "voc_stft_513 = voc_mag_513 * np.exp(1j * mix_phase_513)\n",
    "\n",
    "voc_audio = librosa.istft(\n",
    "    voc_stft_513,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    win_length=N_FFT,\n",
    "    length=len(y)   # keep same length as input\n",
    ")\n",
    "\n",
    "sf.write(str(OUT_WAV), voc_audio, SR)\n",
    "print(\"Saved:\", OUT_WAV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00efbc5-a7f5-4947-bfe4-81736f4a2e5f",
   "metadata": {},
   "source": [
    "# ONLY TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463e7b0b-7bc2-431e-bffc-24d6e42b9fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üéµ EXTRACTEUR VOCAL U-NET\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrez le titre de la chanson (ex: 'Daft Punk - Get Lucky'):  sherine ala bali\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Recherche de: sherine ala bali\n",
      "[youtube:search] Extracting URL: ytsearch:sherine ala bali\n",
      "[download] Downloading playlist: sherine ala bali\n",
      "[youtube:search] query \"sherine ala bali\": Downloading web client config\n",
      "[youtube:search] query \"sherine ala bali\" page 1: Downloading API JSON\n",
      "[youtube:search] Playlist sherine ala bali: Downloading 1 items of 1\n",
      "[download] Downloading item 1 of 1\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=8qQ3v0o-xPY\n",
      "[youtube] 8qQ3v0o-xPY: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 8qQ3v0o-xPY: Downloading android sdkless player API JSON\n",
      "[youtube] 8qQ3v0o-xPY: Downloading web safari player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 8qQ3v0o-xPY: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 8qQ3v0o-xPY: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 8qQ3v0o-xPY: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] 8qQ3v0o-xPY: Downloading 1 format(s): 251\n",
      "[download] Destination: downloads/Sherine - 3la Bali ÔΩú ÿ¥Ÿäÿ±ŸäŸÜ - ÿπŸÑŸâ ÿ®ÿßŸÑŸä.webm\n",
      "[download] 100% of    4.61MiB in 00:00:00 at 19.97MiB/s  \n",
      "[ExtractAudio] Destination: downloads/Sherine - 3la Bali ÔΩú ÿ¥Ÿäÿ±ŸäŸÜ - ÿπŸÑŸâ ÿ®ÿßŸÑŸä.mp3\n",
      "Deleting original file downloads/Sherine - 3la Bali ÔΩú ÿ¥Ÿäÿ±ŸäŸÜ - ÿπŸÑŸâ ÿ®ÿßŸÑŸä.webm (pass -k to keep)\n",
      "[download] Finished downloading playlist: sherine ala bali\n",
      "‚úÖ T√©l√©charg√©: downloads/Sherine - 3la Bali ÔΩú ÿ¥Ÿäÿ±ŸäŸÜ - ÿπŸÑŸâ ÿ®ÿßŸÑŸä.mp3\n",
      "\n",
      "üéØ Fichier source: downloads/Sherine - 3la Bali ÔΩú ÿ¥Ÿäÿ±ŸäŸÜ - ÿπŸÑŸâ ÿ®ÿßŸÑŸä.mp3\n",
      "üéØ Fichier vocal de sortie: vocals_Sherine_-_3la_Bali_ÔΩú_ÿ¥Ÿäÿ±ŸäŸÜ_-_ÿπŸÑŸâ_ÿ®ÿßŸÑŸä.wav\n",
      "üß† Chargement du mod√®le U-Net...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42813/3531239093.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîä Chargement et traitement audio...\n",
      "ü§ñ Inf√©rence en cours (2987 trames)...\n",
      "üîß Reconstruction du signal audio...\n",
      "\n",
      "==================================================\n",
      "‚úÖ VOCAUX EXTRAITS : vocals_Sherine_-_3la_Bali_ÔΩú_ÿ¥Ÿäÿ±ŸäŸÜ_-_ÿπŸÑŸâ_ÿ®ÿßŸÑŸä.wav\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import yt_dlp\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from model import UNet\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Fonction pour t√©l√©charger depuis YouTube\n",
    "# =========================\n",
    "def download_from_youtube(query, output_dir=\"downloads\"):\n",
    "    \"\"\"T√©l√©charge un MP3 depuis YouTube bas√© sur une recherche\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': os.path.join(output_dir, '%(title)s.%(ext)s'),\n",
    "        'quiet': False,\n",
    "        'no_warnings': False,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'default_search': 'ytsearch1',  # Prend le premier r√©sultat\n",
    "        'noplaylist': True,\n",
    "        'extract_flat': False,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            print(f\" Recherche de: {query}\")\n",
    "            info = ydl.extract_info(f\"ytsearch:{query}\", download=True)\n",
    "            \n",
    "            # Trouver le fichier t√©l√©charg√©\n",
    "            downloaded_files = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('.mp3')]\n",
    "            if downloaded_files:\n",
    "                latest_file = max(downloaded_files, key=os.path.getctime)\n",
    "                print(f\" T√©l√©charg√©: {latest_file}\")\n",
    "                return latest_file\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur de t√©l√©chargement: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Demander le titre √† l'utilisateur\n",
    "# =========================\n",
    "print(\"=\" * 50)\n",
    "print(\"EXTRACTEUR VOCAL U-NET\")\n",
    "print(\"=\" * 50)\n",
    "song_title = input(\"Entrez le titre de la chanson (ex: 'Daft Punk - Get Lucky'): \").strip()\n",
    "\n",
    "if not song_title:\n",
    "    print(\"Aucun titre fourni. Arr√™t.\")\n",
    "    exit(1)\n",
    "\n",
    "# T√©l√©charger la chanson\n",
    "mp3_path = download_from_youtube(song_title)\n",
    "if mp3_path is None:\n",
    "    print(\"Impossible de t√©l√©charger la chanson. Arr√™t.\")\n",
    "    exit(1)\n",
    "\n",
    "# =========================\n",
    "# Paths (maintenant bas√©s sur le fichier t√©l√©charg√©)\n",
    "# =========================\n",
    "MP3_PATH = Path(mp3_path)\n",
    "MODEL_PATH = Path(\"unet_final.pth\")\n",
    "\n",
    "# Cr√©er un nom de sortie bas√© sur le titre\n",
    "base_name = MP3_PATH.stem.replace(\" \", \"_\")\n",
    "OUT_WAV = Path(f\"vocals_{base_name}.wav\")\n",
    "\n",
    "print(f\"\\nüéØ Fichier source: {MP3_PATH}\")\n",
    "print(f\"üéØ Fichier vocal de sortie: {OUT_WAV}\")\n",
    "\n",
    "# =========================\n",
    "# Params (must match training)\n",
    "# =========================\n",
    "SR = 8192\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 768\n",
    "\n",
    "FRAME_SIZE = 128          # model patch width in frames\n",
    "STRIDE_FRAMES = 1        # overlap-add stride in frames (32/64 good for speed)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load model\n",
    "# =========================\n",
    "print(\" Chargement du mod√®le U-Net\")\n",
    "model = UNet().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load mp3 -> STFT (513 bins)\n",
    "# =========================\n",
    "print(\"Chargement et traitement audio...\")\n",
    "y, _ = librosa.load(str(MP3_PATH), sr=SR, mono=True)\n",
    "\n",
    "stft_mix = librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "mix_mag_513 = np.abs(stft_mix).astype(np.float32)          # (513, T)\n",
    "mix_phase_513 = np.angle(stft_mix).astype(np.float32)      # (513, T)\n",
    "\n",
    "mix_max = float(mix_mag_513.max() + 1e-8)                  # avoid div by 0\n",
    "mix_mag_513_norm = (mix_mag_513 / mix_max).astype(np.float32)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Drop Nyquist bin for the model (512 bins)\n",
    "# =========================\n",
    "mix_mag_512 = mix_mag_513_norm[:-1, :]                     # (512, T)\n",
    "F, T = mix_mag_512.shape\n",
    "assert F == 512, f\"Expected 512 bins for model input, got {F}\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Patch-based inference (overlap-add) in 512-bin space\n",
    "# =========================\n",
    "print(f\" Inf√©rence en cours ({T} trames)...\")\n",
    "voc_norm_512 = np.zeros((F, T), dtype=np.float32)\n",
    "weight = np.zeros((F, T), dtype=np.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t0 in range(0, T - FRAME_SIZE + 1, STRIDE_FRAMES):\n",
    "        mix_patch = mix_mag_512[:, t0:t0 + FRAME_SIZE]  # (512, 128)\n",
    "        mix_t = torch.from_numpy(mix_patch).unsqueeze(0).unsqueeze(0).to(DEVICE)  # (1,1,512,128)\n",
    "\n",
    "        mask_patch = model(mix_t).squeeze().cpu().numpy().astype(np.float32)      # (512,128)\n",
    "        voc_patch = mask_patch * mix_patch                                        # (512,128)\n",
    "\n",
    "        voc_norm_512[:, t0:t0 + FRAME_SIZE] += voc_patch\n",
    "        weight[:, t0:t0 + FRAME_SIZE] += 1.0\n",
    "\n",
    "# Normalisation finale\n",
    "voc_norm_512 /= np.maximum(weight, 1.0)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# De-normalize + restore Nyquist bin + ISTFT (n_fft=1024)\n",
    "# =========================\n",
    "print(\" Reconstruction du signal audio...\")\n",
    "voc_mag_512 = voc_norm_512 * mix_max                        # back to original scale\n",
    "\n",
    "nyquist_row = np.zeros((1, T), dtype=np.float32)\n",
    "voc_mag_513 = np.vstack([voc_mag_512, nyquist_row])         # (513, T)\n",
    "\n",
    "voc_stft_513 = voc_mag_513 * np.exp(1j * mix_phase_513)\n",
    "\n",
    "voc_audio = librosa.istft(\n",
    "    voc_stft_513,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    win_length=N_FFT,\n",
    "    length=len(y)   # keep same length as input\n",
    ")\n",
    "\n",
    "# Sauvegarde\n",
    "sf.write(str(OUT_WAV), voc_audio, SR)\n",
    "\n",
    "print(f\" VOCAUX EXTRAITS : {OUT_WAV}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d44fff-7ba7-4a56-840c-b8516e1d6acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
